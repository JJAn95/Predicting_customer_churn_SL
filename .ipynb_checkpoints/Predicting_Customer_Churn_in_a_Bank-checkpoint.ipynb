{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e674107d",
   "metadata": {},
   "source": [
    "Ссылка на репозиторий Github\n",
    "\n",
    "https://github.com/JJAn95/supervised_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5514f2cf",
   "metadata": {},
   "source": [
    "## Вступление"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11714912",
   "metadata": {},
   "source": [
    "**Описание**\n",
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Нам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. Необходимо построить модель с предельно большим значением F1-меры.\n",
    "Дополнительно необходимо измерять AUC-ROC, сравнивать её значение с F1-мерой.\n",
    "\n",
    "**Цель:** Найти и построить модель с максимально большим значением F1-меры.\n",
    "\n",
    "**План действий:**\n",
    "\n",
    "1. Открыть и изучить файл с данными.\n",
    "2. Подготовить данные. Пояснить порядок действий.\n",
    "3. Исследовать баланс классов, обучить модель без учёта дисбаланса. Кратко описать выводы.\n",
    "4. Улучшить качество модели, учитывая дисбаланс классов. Обучить разные модели и найти лучшую. Кратко описать выводы.\n",
    "5. Провести финальное тестирование."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35241d23",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1485e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем все необходимые библиотеки\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c59eb459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# открываем и чекаем исходный датасет\n",
    "try:\n",
    "    data = pd.read_csv('Churn.csv')\n",
    "except FileNotFoundError:\n",
    "    data = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f34f74",
   "metadata": {},
   "source": [
    "**Признаки**\n",
    "- RowNumber — индекс строки в данных\n",
    "- CustomerId — уникальный идентификатор клиента\n",
    "- Surname — фамилия\n",
    "- CreditScore — кредитный рейтинг\n",
    "- Geography — страна проживания\n",
    "- Gender — пол\n",
    "- Age — возраст\n",
    "- Tenure — сколько лет человек является клиентом банка\n",
    "- Balance — баланс на счёте\n",
    "- NumOfProducts — количество продуктов банка, используемых клиентом\n",
    "- HasCrCard — наличие кредитной карты\n",
    "- IsActiveMember — активность клиента\n",
    "- EstimatedSalary — предполагаемая зарплата\n",
    "\n",
    "**Целевой признак**\n",
    "- Exited — факт ухода клиента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e4c22ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99604bfc",
   "metadata": {},
   "source": [
    "В целом данные хорошие. Полные, на первый взгляд тип данных везде верный. Но видим, что в столбце Tenure у нас есть пропуски. Так же. можно предположить, что для построения модели нам не нужны следующие данные: RowNumber, CustomerId, Surname. Это конечно будет крипово, если мы найдем какую-то закономерность между уходом клиента и его фамилий и idв базе, но нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "494e738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "# data_model.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061b0a1a",
   "metadata": {},
   "source": [
    "Далее изучим, какие значения у нас хранятся в Tenure, там где есть пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "63cd0247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     952\n",
       "2.0     950\n",
       "8.0     933\n",
       "3.0     928\n",
       "5.0     927\n",
       "7.0     925\n",
       "4.0     885\n",
       "9.0     882\n",
       "6.0     881\n",
       "10.0    446\n",
       "0.0     382\n",
       "Name: Tenure, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model['Tenure'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae0165",
   "metadata": {},
   "source": [
    "В целом, видим, что значения у нас все целые. Поэтому думаю можно заполнить пропуски медианным значением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "74176743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_model['Tenure'] = data_model['Tenure'].fillna(data_model['Tenure'].median())\n",
    "# data_model['Tenure'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28e13ba",
   "metadata": {},
   "source": [
    "При таком подходе мне не понравилось, что у нас просто все 900+ пропусков плюсанулись к значению 5, поэтому я решил заполнить медианным значением в зависимости от пола, страны и возраста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2823a2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0     1282\n",
       "4.0     1166\n",
       "6.0     1097\n",
       "2.0      958\n",
       "1.0      956\n",
       "8.0      946\n",
       "7.0      945\n",
       "3.0      936\n",
       "9.0      883\n",
       "10.0     446\n",
       "0.0      382\n",
       "Name: Tenure, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model['Tenure'] = data_model.groupby(['Gender', 'Geography', 'Age'])['Tenure'].apply(lambda x: x.fillna(x.median())).round()\n",
    "data_model['Tenure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9f890e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  float64\n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# data_model.info()\n",
    "\n",
    "# Осталось еще 3 пропуска. Их уж можно заменить общим медианым знаечнием, раз уж из группировки не нашлось\n",
    "data_model['Tenure'] = data_model['Tenure'].fillna(data_model['Tenure'].median())\n",
    "\n",
    "data_model.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2872af",
   "metadata": {},
   "source": [
    "Стало получше, так хоть у нас нет значения, которое минимум в 2 раза отличается от остальных.\n",
    "\n",
    "Изучим категориальные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "05071ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: Geography, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model['Geography'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "df460704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      5457\n",
       "Female    4543\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccba705b",
   "metadata": {},
   "source": [
    "Думаю можно закодировать эти номинальные категориальные данные: Geography и Gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e4a1b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # номинальные переменные поэтому применяем OHE\n",
    "# future_ohe = ['Geography', 'Gender']\n",
    "# print(data_model.shape)\n",
    "# # print(data_model.head(10))\n",
    "# data_model = pd.get_dummies(data_model, drop_first=True, columns=future_ohe)\n",
    "# print(data_model.shape)\n",
    "# # print(data_model.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ccdb17",
   "metadata": {},
   "source": [
    "По размерам данных все гуд. Был один столбец со страной проживания - появилось два, так как мы учли ловушку. и из одного столбца с полом тоже, с учетом ловушки остался один столбец. Итого размерность увеличилась на 1 столбец."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf94f0",
   "metadata": {},
   "source": [
    "Исследуем баланс классов теперь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d758ba37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.7963\n",
       "1    0.2037\n",
       "Name: Exited, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model['Exited'].value_counts() / data_model.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81e6bf8",
   "metadata": {},
   "source": [
    "В целом да, видим дисбаланс классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cd8435",
   "metadata": {},
   "source": [
    "## Разделяем исходные данные на обучающую, валидационную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "22d982b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим выборку на валидационную и тестовую.\n",
    "data_train, data_test = train_test_split(data_model, test_size=0.2, random_state=12345, stratify=data['Exited'])\n",
    "data_train, data_valid = train_test_split(data_train, test_size=0.25, random_state=12345, stratify=data_train['Exited'])\n",
    "\n",
    "#  Определим зависимую и независимые переменные для выделенных датасетов\n",
    "X_train = data_train.drop(['Exited'], axis=1)\n",
    "Y_train = data_train['Exited']\n",
    "X_test = data_test.drop(['Exited'], axis=1)\n",
    "Y_test = data_test['Exited']\n",
    "X_valid = data_valid.drop(['Exited'], axis=1)\n",
    "Y_valid = data_valid['Exited']\n",
    "\n",
    "# Создадим словарь на будущее: модель - качество\n",
    "sl = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d32494ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance',\n",
      "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# # # Разделим выборку на валидационную и тестовую.\n",
    "# # data_train, data_test = train_test_split(data_model, test_size=0.2, random_state=12345, stratify=data['Exited'])\n",
    "# # data_train, data_valid = train_test_split(data_train, test_size=0.25, random_state=12345, stratify=data_train['Exited'])\n",
    "\n",
    "# # # Создаем объект OneHotEncoder\n",
    "# # ohe = OneHotEncoder()\n",
    "\n",
    "# # # Преобразуем столбцы 'Geography' и 'Gender'\n",
    "# # X_train_encoded = ohe.fit_transform(data_train[['Geography', 'Gender']])\n",
    "# # print(X_train_encoded.shape)\n",
    "# # X_valid_encoded = ohe.transform(data_valid[['Geography', 'Gender']])\n",
    "# # print(X_valid_encoded.shape)\n",
    "# # X_test_encoded = ohe.transform(data_test[['Geography', 'Gender']])\n",
    "# # print(X_test_encoded.shape)\n",
    "\n",
    "# # # Создаем новые датафреймы с закодированными столбцами\n",
    "# # X_train = pd.concat([data_train.drop(['Geography', 'Gender', 'Exited'], axis=1), \n",
    "# #                      pd.DataFrame(X_train_encoded.toarray())], axis=1)\n",
    "# # print(X_train.shape)\n",
    "# # print(X_train.drop_duplicates().shape)\n",
    "# # X_valid = pd.concat([data_valid.drop(['Geography', 'Gender', 'Exited'], axis=1), \n",
    "# #                      pd.DataFrame(X_valid_encoded.toarray())], axis=1)\n",
    "# # print(X_valid.shape)\n",
    "# # print(X_valid.drop_duplicates().shape)\n",
    "# # X_test = pd.concat([data_test.drop(['Geography', 'Gender', 'Exited'], axis=1), \n",
    "# #                     pd.DataFrame(X_test_encoded.toarray())], axis=1)\n",
    "# # print(X_test.shape)\n",
    "# # print(X_test.drop_duplicates().shape)\n",
    "\n",
    "# # # Определяем целевую переменную\n",
    "# # y_train = data_train['Exited']\n",
    "# # y_valid = data_valid['Exited']\n",
    "# # y_test = data_test['Exited']\n",
    "\n",
    "# # Нормализуем значения\n",
    "# norm = Normalizer().fit(X_train)\n",
    "# X_train = norm.transform(X_train)\n",
    "# X_test = norm.transform(X_test)\n",
    "# X_valid = norm.transform(X_valid)\n",
    "\n",
    "\n",
    "# # Создадим словарь на будущее: модель - качество\n",
    "# sl = {}\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f557650c",
   "metadata": {},
   "source": [
    "Перекодируем данные методом OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "56d892a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianan/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "features_categirical = ['Geography', 'Gender']\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False, drop='first')\n",
    "ohe.fit(X_train[features_categirical])\n",
    "\n",
    "def features_ohe(ohe_variable, df_features, features_categ):\n",
    "    df_features_ohe = pd.DataFrame(\n",
    "        data=ohe_variable.transform(df_features[features_categ]), \n",
    "        index=df_features.index,\n",
    "        columns=ohe_variable.get_feature_names_out()\n",
    "    )\n",
    "\n",
    "    df_features = df_features.drop(features_categ, axis=1)\n",
    "    df_features = df_features.join(df_features_ohe)\n",
    "    return df_features    \n",
    "\n",
    "X_train = features_ohe(ohe, X_train, features_categirical)\n",
    "X_valid = features_ohe(ohe, X_valid, features_categirical)\n",
    "X_test = features_ohe(ohe, X_test, features_categirical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66eb73f",
   "metadata": {},
   "source": [
    "Стандартизируем количественные данные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4cbe4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[numeric])\n",
    "\n",
    "X_train[numeric] = scaler.transform(X_train[numeric])\n",
    "X_valid[numeric] = scaler.transform(X_valid[numeric])\n",
    "X_test[numeric] = scaler.transform(X_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcd6ca1",
   "metadata": {},
   "source": [
    "## Построение изученных моделей для классификации. Исследуем их качество (f1_score)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b955ef",
   "metadata": {},
   "source": [
    "### Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c1ec91cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.593342981186686\n",
      "{'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 7}\n"
     ]
    }
   ],
   "source": [
    "# Перебираем гиперпараметры и выбираем модель с максимальным значением f1_score, запоминая гипперпараметры такой модели\n",
    "\n",
    "best_res = 0\n",
    "good_tree = None\n",
    "for depth in range(1,10):\n",
    "    for split in range(2,10):\n",
    "        for leaf in range(1,10):\n",
    "            model = DecisionTreeClassifier(max_depth=depth, \n",
    "                                           min_samples_split=split, \n",
    "                                           min_samples_leaf=leaf, \n",
    "                                           criterion='gini',\n",
    "                                           random_state=12345)\n",
    "            model.fit(X_train, Y_train)\n",
    "            pred_valid = model.predict(X_valid)\n",
    "            res = f1_score(Y_valid, pred_valid)\n",
    "            if res > best_res:\n",
    "                best_valid = pred_valid\n",
    "                best_res = res\n",
    "                best_params = {'max_depth': depth, 'min_samples_split': split, 'min_samples_leaf': leaf}\n",
    "                good_tree = model\n",
    "\n",
    "print(best_res)                \n",
    "print(best_params)\n",
    "sl['Decision Tree'] = [best_res, best_params, good_tree]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0e672d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC для решаюшего дерева: 0.8281170230322772\n"
     ]
    }
   ],
   "source": [
    "Y_prob = good_tree.predict_proba(X_valid)[:, 1]\n",
    "auc_roc = roc_auc_score(Y_valid, Y_prob)\n",
    "print(\"AUC-ROC для решаюшего дерева:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3b2d41",
   "metadata": {},
   "source": [
    "Получили наилушее значение f1_score = 0.593342981186686, при глубине = 8, мин количестве узлов = 2 и мин колве листьев = 7. Значение AUC-ROC - 0.8281170230322772. Оба показатели достаточно хорошие. f1_score больше 0.5, а AUC-ROC очень близко к 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d968e7f4",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8a7b5647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5884146341463414\n",
      "{'n_estimators': 50, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "best_res = 0\n",
    "good_forest = None\n",
    "for est in range(10,51,10):\n",
    "    for depth in range(1, 16):\n",
    "        for split in range(2,5):\n",
    "            for leaf in range(1,5):\n",
    "                model = RandomForestClassifier(n_estimators=est,\n",
    "                                               min_samples_split=split,\n",
    "                                               max_depth=depth,\n",
    "                                               min_samples_leaf=leaf,\n",
    "                                               random_state=12345)\n",
    "                model.fit(X_train, Y_train)\n",
    "                pred_valid = model.predict(X_valid)\n",
    "                res = f1_score(Y_valid, pred_valid)\n",
    "                if res > best_res:\n",
    "                    best_valid = pred_valid\n",
    "                    good_forest = model\n",
    "                    best_res = res\n",
    "                    best_params = {'n_estimators': est, 'max_depth': depth, \n",
    "                                   'min_samples_split': split, 'min_samples_leaf': leaf}\n",
    "print(best_res)                \n",
    "print(best_params)\n",
    "sl['Random Forest'] = [best_res, best_params, good_forest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f653d44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC для случайного леса: 0.8580922987702648\n"
     ]
    }
   ],
   "source": [
    "Y_prob = good_forest.predict_proba(X_valid)[:, 1]\n",
    "auc_roc = roc_auc_score(Y_valid, Y_prob)\n",
    "print(\"AUC-ROC для случайного леса:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb174ee",
   "metadata": {},
   "source": [
    "Получили наилушее значение f1_score = 0.5884146341463414, при колве деревьев = 50, глубине = 15, мин количеству узлов = 4 и мин колве листьев = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47001200",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "88ec50e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3214953271028037\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345)\n",
    "model.fit(X_train, Y_train)\n",
    "pred_valid = model.predict(X_valid)\n",
    "res = f1_score(Y_valid, pred_valid)\n",
    "print(res)\n",
    "\n",
    "sl['Logistic Regression'] = [res, model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "910cecd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC для логистической регрессии: 0.7874808552774655\n"
     ]
    }
   ],
   "source": [
    "Y_prob = model.predict_proba(X_valid)[:, 1]\n",
    "auc_roc = roc_auc_score(Y_valid, Y_prob)\n",
    "print(\"AUC-ROC для логистической регрессии:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f3cfd4",
   "metadata": {},
   "source": [
    "Получили наилушее значение f1_score = 0.3214953271028037. А значение AUC-ROC: 0.7874808552774655."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7e57d4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "f1_score =  0.593342981186686\n"
     ]
    }
   ],
   "source": [
    "max_key = max(sl.items(), key=lambda x: x[1][0])[0]\n",
    "print(max_key)\n",
    "print('f1_score = ', sl[max_key][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c847c6a",
   "metadata": {},
   "source": [
    "Самая лучшая модель получилась - Решающее дерево. Со значением метрики F1 = 0.593342981186686. Проверим модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "61034f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на тестовой выборке: 0.5911047345767575\n"
     ]
    }
   ],
   "source": [
    "pred_test = good_tree.predict(X_test)\n",
    "f1 = f1_score(Y_test, pred_test)\n",
    "print(\"f1_score на тестовой выборке:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f214c",
   "metadata": {},
   "source": [
    "Значение f1_score на тестовой выборке получилось 0.5911047345767575. Неплохой результат, но теперь посомтрим, что изменится, если мы учтем дисбаланс классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba2e3f5",
   "metadata": {},
   "source": [
    "## Балансировка классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c5cd6bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.7963\n",
       "1    0.2037\n",
       "Name: Exited, dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model['Exited'].value_counts() / data_model.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5d4829",
   "metadata": {},
   "source": [
    "Помним, что классы у нас были не сбалансированы, поэтому попробуем их все же сбалансирвоать методом upsampling. То есть увеличим частоту положительных ответов на равне с отрицательными. У нас уже есть разделенные выборки. Осталось написать алгоритм для повышения частоты положительных. Так как видим, что 0-ей в 4 раза больше чем 1, то и увеличивать выборку будем в 4 раза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d3ee19d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 11)\n",
      "(6000,)\n",
      "(9669, 11)\n",
      "(9669,)\n"
     ]
    }
   ],
   "source": [
    "def upsample(X_train, Y_train, repeat):\n",
    "    X_zeros = X_train[Y_train == 0]\n",
    "    X_ones = X_train[Y_train == 1]\n",
    "    Y_zeros = Y_train[Y_train == 0]\n",
    "    Y_ones = Y_train[Y_train == 1]\n",
    "\n",
    "    #repeat = 10\n",
    "    X_upsampled = pd.concat([pd.DataFrame(X_zeros)] + [pd.DataFrame(X_ones)] * repeat)\n",
    "    Y_upsampled = pd.concat([Y_zeros] + [Y_ones] * repeat)\n",
    "    \n",
    "# < добавьте перемешивание >\n",
    "    X_upsampled, Y_upsampled = shuffle(X_upsampled, Y_upsampled, random_state=12345)\n",
    "    return X_upsampled, Y_upsampled\n",
    "    \n",
    "X_upsampled, Y_upsampled = upsample(X_train, Y_train, 4)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_upsampled.shape)\n",
    "print(Y_upsampled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4a0003",
   "metadata": {},
   "source": [
    "Видим, что искусственное увеличение класса прошло успешно. Количество независимых и зависимой переменной одинаков увеличилось. Было 6000 строк - стало 9669. Теперь повторим предыдущие шаги с обучением разных моделей с выявлением наилучшей модели для данной задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9f86e8",
   "metadata": {},
   "source": [
    "## Построение изученных моделей для классификации на сбалансирвоанных выборках. Исследуем их качество (f1_score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5765c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_balance = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80587140",
   "metadata": {},
   "source": [
    "### Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "56e38250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5796064400715564\n",
      "{'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 3}\n"
     ]
    }
   ],
   "source": [
    "# Перебираем гиперпараметры и выбираем модель с максимальным значением f1_score, запоминая гипперпараметры такой модели\n",
    "\n",
    "best_res = 0\n",
    "good_tree_balance = None\n",
    "for depth in range(1,16):\n",
    "    for split in range(2,10):\n",
    "        for leaf in range(1,10):\n",
    "            model = DecisionTreeClassifier(max_depth=depth, \n",
    "                                           min_samples_split=split, \n",
    "                                           min_samples_leaf=leaf, \n",
    "                                           criterion='gini',\n",
    "                                           random_state=12345)\n",
    "            model.fit(X_upsampled, Y_upsampled)\n",
    "            pred_valid = model.predict(X_valid)\n",
    "            res = f1_score(Y_valid, pred_valid)\n",
    "            if res > best_res:\n",
    "                best_valid = pred_valid\n",
    "                best_res = res\n",
    "                best_params = {'max_depth': depth, 'min_samples_split': split, 'min_samples_leaf': leaf}\n",
    "                good_tree_balance = model\n",
    "\n",
    "print(best_res)                \n",
    "print(best_params)\n",
    "sl_balance['Decision Tree'] = [best_res, best_params, good_tree_balance]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c48ca29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC для решающего дерева: 0.8409580612970443\n"
     ]
    }
   ],
   "source": [
    "Y_prob = good_tree_balance.predict_proba(X_valid)[:, 1]\n",
    "auc_roc = roc_auc_score(Y_valid, Y_prob)\n",
    "print(\"AUC-ROC для решающего дерева:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5e39d2",
   "metadata": {},
   "source": [
    "Получили наилушее значение f1_score = 0.5796064400715564, при глубине = 6, мин количеству узлов = 2 и мин колве листьев = 3. Здесь результаты получились похуже, чем у такой же модели, но без балансирвоки. Метрика AUC-ROC для решающего дерева: 0.8409580612970443."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e4cfe1",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dfbca5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6362649294245385\n",
      "{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}\n"
     ]
    }
   ],
   "source": [
    "best_res = 0\n",
    "good_forest_balance = None\n",
    "for est in range(10,51,10):\n",
    "    for depth in range(1, 16):\n",
    "        for split in range(2,5):\n",
    "            for leaf in range(1,3):\n",
    "                model = RandomForestClassifier(n_estimators=est,\n",
    "                                               min_samples_split=split,\n",
    "                                               max_depth=depth,\n",
    "                                               min_samples_leaf=leaf,\n",
    "                                               random_state=12345)\n",
    "                model.fit(X_upsampled, Y_upsampled)\n",
    "                pred_valid = model.predict(X_valid)\n",
    "                res = f1_score(Y_valid, pred_valid)\n",
    "                if res > best_res:\n",
    "                    best_valid = pred_valid\n",
    "                    good_forest_balance = model\n",
    "                    best_res = res\n",
    "                    best_params = {'n_estimators': est, 'max_depth': depth, \n",
    "                                   'min_samples_split': split, 'min_samples_leaf': leaf}\n",
    "print(best_res)                \n",
    "print(best_params)\n",
    "sl_balance['Random Forest'] = [best_res, best_params, good_forest_balance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c81fb177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC для случайного леса: 0.8701336158963278\n"
     ]
    }
   ],
   "source": [
    "Y_prob = good_forest_balance.predict_proba(X_valid)[:, 1]\n",
    "auc_roc = roc_auc_score(Y_valid, Y_prob)\n",
    "print(\"AUC-ROC для случайного леса:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61abddc1",
   "metadata": {},
   "source": [
    "Получили наилушее значение f1_score = 0.6362649294245385, при колве деревьев = 50, глубине = 10, мин количеству узлов = 2 и мин колве листьев = 2. Здесь результат наоборот получился лучше, чем в модели с несбалансирвоанными классами. AUC-ROC для случайного леса: 0.8701336158963278"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e02c50",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8b20f354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5081545064377684\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(X_upsampled, Y_upsampled)\n",
    "pred_valid = model.predict(X_valid)\n",
    "res = f1_score(Y_valid, pred_valid)\n",
    "print(res)\n",
    "\n",
    "sl_balance['Logistic Regression'] = [res, model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4fff6892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC для логистической регрессии: 0.7918442325221986\n"
     ]
    }
   ],
   "source": [
    "Y_prob = model.predict_proba(X_valid)[:, 1]\n",
    "auc_roc = roc_auc_score(Y_valid, Y_prob)\n",
    "print(\"AUC-ROC для логистической регрессии:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fef53d2",
   "metadata": {},
   "source": [
    "Получили значение f1_score = 0.5081545064377684. AUC-ROC для логистической регрессии: 0.7918442325221986."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "15f59af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "f1_score =  0.6362649294245385\n"
     ]
    }
   ],
   "source": [
    "max_key_balance = max(sl_balance.items(), key=lambda x: x[1][0])[0]\n",
    "print(max_key_balance)\n",
    "print('f1_score = ', sl_balance[max_key_balance][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502201be",
   "metadata": {},
   "source": [
    "После балансирвоки классов самой лучшей моделью стал - Случайный лес. Со значением метрики F1 = 0.6362649294245385."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3b095895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на тестовой выборке: 0.6362649294245385\n"
     ]
    }
   ],
   "source": [
    "pred_test = good_forest_balance.predict(X_valid)\n",
    "f1 = f1_score(Y_valid, pred_test)\n",
    "print(\"f1_score на тестовой выборке:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0c777dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_list = [f1]\n",
    "auc_roc_list = [auc_roc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c726083",
   "metadata": {},
   "source": [
    "Судя по результату AUC-ROC, то наша наилучшея модель довольно неплохо различает классы \"1\" и \"0\". Наше значение довольно близко к значению 1. А вот значение f1_score плоховато. Во-первых, оно меньше 0.59 (пороговое значение), а во-вторых в целом такое значение не очень хорошо, так как довольно далеко от идеальной единицы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec481d",
   "metadata": {},
   "source": [
    " ## Попробуем занизить класс \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "94abeee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [pd.DataFrame(features_zeros).sample(frac=fraction, random_state=12345)] + [pd.DataFrame(features_ones)])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "X_downsampled, Y_downsampled = downsample(X_train, Y_train, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "19d88aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 11)\n",
      "(6000,)\n",
      "(2417, 11)\n",
      "(2417,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_downsampled.shape)\n",
    "print(Y_downsampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0df28",
   "metadata": {},
   "source": [
    "Проверили размерность выборки. Выглядит все гуд. Теперь обучим заново три модели по \"заниженной\" выборке, также найдем лучшую модель и посмотрим на прогноз по тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a35d73",
   "metadata": {},
   "source": [
    "### Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2d6bc7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5969543147208122\n",
      "{'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 8}\n"
     ]
    }
   ],
   "source": [
    "# Перебираем гиперпараметры и выбираем модель с максимальным значением f1_score, запоминая гипперпараметры такой модели\n",
    "\n",
    "best_res = 0\n",
    "good_tree_balance2 = None\n",
    "for depth in range(1,10):\n",
    "    for split in range(2,10):\n",
    "        for leaf in range(1,10):\n",
    "            model = DecisionTreeClassifier(max_depth=depth, \n",
    "                                           min_samples_split=split, \n",
    "                                           min_samples_leaf=leaf, \n",
    "                                           criterion='gini',\n",
    "                                           random_state=12345)\n",
    "            model.fit(X_downsampled, Y_downsampled)\n",
    "            pred_valid = model.predict(X_valid)\n",
    "            res = f1_score(Y_valid, pred_valid)\n",
    "            if res > best_res:\n",
    "                best_valid = pred_valid\n",
    "                best_res = res\n",
    "                best_params = {'max_depth': depth, 'min_samples_split': split, 'min_samples_leaf': leaf}\n",
    "                good_tree_balance2 = model\n",
    "\n",
    "print(best_res)                \n",
    "print(best_params)\n",
    "sl_balance['Decision Tree downsampling'] = [best_res, best_params, good_tree_balance2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9f81df70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC для решающего дерева downsampling '0': 0.8458435322842103\n"
     ]
    }
   ],
   "source": [
    "Y_prob = good_tree_balance2.predict_proba(X_valid)[:, 1]\n",
    "auc_roc = roc_auc_score(Y_valid, Y_prob)\n",
    "print(\"AUC-ROC для решающего дерева downsampling '0':\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f5f16",
   "metadata": {},
   "source": [
    "Получили неплохой и максимально возможный результат в 0.5969543147208122, при глубине = 6, мин колве узлов = 2 и мин колве листьев =8. AUC-ROC для решающего дерева downsampling '0': 0.8458435322842103."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811fbfd7",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "72deaf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6251256281407036\n",
      "{'n_estimators': 50, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "best_res = 0\n",
    "good_forest_balance2 = None\n",
    "for est in range(10,51,10):\n",
    "    for depth in range(1, 16):\n",
    "        for split in range(2,5):\n",
    "            for leaf in range(1,3):\n",
    "                model = RandomForestClassifier(n_estimators=est,\n",
    "                                               min_samples_split=split,\n",
    "                                               max_depth=depth,\n",
    "                                               min_samples_leaf=leaf,\n",
    "                                               random_state=12345)\n",
    "                model.fit(X_downsampled, Y_downsampled)\n",
    "                pred_valid = model.predict(X_valid)\n",
    "                res = f1_score(Y_valid, pred_valid)\n",
    "                if res > best_res:\n",
    "                    best_valid = pred_valid\n",
    "                    good_forest_balance2 = model\n",
    "                    best_res = res\n",
    "                    best_params = {'n_estimators': est, 'max_depth': depth, \n",
    "                                   'min_samples_split': split, 'min_samples_leaf': leaf}\n",
    "print(best_res)                \n",
    "print(best_params)\n",
    "sl_balance['Random Forest downsampling'] = [best_res, best_params, good_forest_balance2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "90edd487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC для случайного леса downsampling '0': 0.8703187008271754\n"
     ]
    }
   ],
   "source": [
    "Y_prob = good_forest_balance2.predict_proba(X_valid)[:, 1]\n",
    "auc_roc = roc_auc_score(Y_valid, Y_prob)\n",
    "print(\"AUC-ROC для случайного леса downsampling '0':\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1e6597",
   "metadata": {},
   "source": [
    "Получили результат получше в 0.6251256281407036, при колве деревьев = 50, глубине = 8, мин колве узлов = 3 и мин колве листьев = 1. AUC-ROC для случайного леса downsampling '0': 0.8703187008271754"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc339bef",
   "metadata": {},
   "source": [
    "### Логистическая регерссия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7b996568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5047210300429185\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(X_downsampled, Y_downsampled)\n",
    "pred_valid = model.predict(X_valid)\n",
    "res = f1_score(Y_valid, pred_valid)\n",
    "print(res)\n",
    "\n",
    "sl_balance['Logistic Regression downsampling'] = [res, model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "62c36dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC для логистической регрессии downsampling '0': 0.7913244523414015\n"
     ]
    }
   ],
   "source": [
    "Y_prob = model.predict_proba(X_valid)[:, 1]\n",
    "auc_roc = roc_auc_score(Y_valid, Y_prob)\n",
    "print(\"AUC-ROC для логистической регрессии downsampling '0':\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9adef4",
   "metadata": {},
   "source": [
    "Визуально здесь получился снова не самый лучший результат - 0.5047210300429185. AUC-ROC для логистической регрессии downsampling '0': 0.7913244523414015.\n",
    "\n",
    "Ищем победителя среди всех обученных моделей.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "23714222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "f1_score =  0.6362649294245385\n"
     ]
    }
   ],
   "source": [
    "max_key_balance2 = max(sl_balance.items(), key=lambda x: x[1][0])[0]\n",
    "print(max_key_balance2)\n",
    "print('f1_score = ', sl_balance[max_key_balance2][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a270bcaa",
   "metadata": {},
   "source": [
    "Им оказался случайный лес при балансирвоке классов методом Upsampling. Предскажем значения на тестовой выбокре, используя модель случайного леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ce2d5293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на тестовой выборке: 0.6247288503253796\n"
     ]
    }
   ],
   "source": [
    "pred_test = good_forest_balance.predict(X_test)\n",
    "f1 = f1_score(Y_test, pred_test)\n",
    "print(\"f1_score на тестовой выборке:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fe7ffc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC для случайного леса уже на тестовой выборке: 0.8637451010332367\n"
     ]
    }
   ],
   "source": [
    "Y_prob = good_forest_balance.predict_proba(X_test)[:, 1]\n",
    "auc_roc = roc_auc_score(Y_test, Y_prob)\n",
    "print(\"AUC-ROC для случайного леса уже на тестовой выборке:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d1911f",
   "metadata": {},
   "source": [
    "Здесь мы уже получаем результат получше. f1 на тестовой выбокре равен - 0.6247288503253796. А AUC-ROC равен - 0.8637451010332367."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03a7136",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "\n",
    "1. Проверили наши данные на пропуски. Заменили пропуски в Tenure медианным значением по сходим параметрам.\n",
    "2. Разбили датафрейм на 3 выборки в классах: обучающую, валидационную и тестовую.\n",
    "3. Закодировали две номинальные категориальные колонки: Geography и Gender. Методом OHE. Пременили стандартизацию количественных данных.\n",
    "\n",
    "\n",
    "4. Построили 3 разных модели без учета дисбаланса классов: Решающее дерево, Случайный лес и Логистическую регрессию. Подобрали оптимальные гиперпарметры для каждой модели, чтобы получить максимальное значение f1 каждой модели для валдационной выборки.\n",
    "5. Определили победителя - Решающее дерево, с f1 на тестовой выборке = 0.59 и гиперпарметрами у модели: глубина = 8, мин количество узлов = 2 и мин колве листьев = 7. И значением AUC-ROC 0.83.\n",
    "\n",
    "\n",
    "6. Изучили дисбаланс классов. Сначала провели балансировку методом upsampling.\n",
    "7. Построили 3 разных модели учетом дисбаланса классов: Решающее дерево, Случайный лес и Логистическую регрессию. Подобрали оптимальные гиперпарметры для каждой модели, чтобы получить максимальное значение f1 каждой модели для валидационной выборки.\n",
    "8. Приняли решение попробовать другой подход в балансировке классов - downsampling.\n",
    "10. Также построили 3 разных модели учетом дисбаланса классов: Решающее дерево, Случайный лес и Логистическую регрессию. Подобрали оптимальные гиперпарметры для каждой модели, чтобы получить максимальное значение f1 каждой модели для валидационной выборки.\n",
    "\n",
    "11. Определили победителя - Случайный лес, построенный на выборках с балансировкой классов методом upsampling, с f1 на валидационной  выборке = 0.63, и с f1 на тестовой выборке = 0.62, auc_roc на тестовой выборке = 0.86 и гиперпарметрами у модели: при колве деревьев = 50, глубине = 10, мин колве узлов = 2 и мин колве листьев = 2.\n",
    "\n",
    "Таким образом, лучшая модель у нас получилась обученная на выборке с балансировкой классов методом upsampling. Алгоритм обучения модели - Случайный лес. Пороговое значение в 0.59 тоже прошли. Успех."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2108,
    "start_time": "2023-04-28T06:24:32.659Z"
   },
   {
    "duration": 132,
    "start_time": "2023-04-28T06:24:34.770Z"
   },
   {
    "duration": 16,
    "start_time": "2023-04-28T06:24:34.904Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-28T06:24:34.922Z"
   },
   {
    "duration": 19,
    "start_time": "2023-04-28T06:24:34.930Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-28T06:24:34.951Z"
   },
   {
    "duration": 161,
    "start_time": "2023-04-28T06:24:34.960Z"
   },
   {
    "duration": 20,
    "start_time": "2023-04-28T06:24:35.123Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-28T06:24:35.145Z"
   },
   {
    "duration": 16,
    "start_time": "2023-04-28T06:24:35.155Z"
   },
   {
    "duration": 20,
    "start_time": "2023-04-28T06:24:35.173Z"
   },
   {
    "duration": 9,
    "start_time": "2023-04-28T06:24:35.195Z"
   },
   {
    "duration": 44,
    "start_time": "2023-04-28T06:24:35.205Z"
   },
   {
    "duration": 33,
    "start_time": "2023-04-28T06:24:35.251Z"
   },
   {
    "duration": 15196,
    "start_time": "2023-04-28T06:24:42.452Z"
   },
   {
    "duration": 180256,
    "start_time": "2023-04-28T06:25:10.161Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-28T06:28:10.419Z"
   },
   {
    "duration": 88,
    "start_time": "2023-04-28T06:28:10.425Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-28T06:28:10.515Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-28T06:28:10.529Z"
   },
   {
    "duration": 15,
    "start_time": "2023-04-28T06:28:10.534Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-28T06:28:10.551Z"
   },
   {
    "duration": 133,
    "start_time": "2023-04-28T06:28:10.557Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-28T06:28:10.692Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-28T06:28:10.706Z"
   },
   {
    "duration": 43,
    "start_time": "2023-04-28T06:28:10.713Z"
   },
   {
    "duration": 14,
    "start_time": "2023-04-28T06:28:10.758Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-28T06:28:10.774Z"
   },
   {
    "duration": 17,
    "start_time": "2023-04-28T06:28:10.784Z"
   },
   {
    "duration": 54,
    "start_time": "2023-04-28T06:28:10.803Z"
   },
   {
    "duration": 10398,
    "start_time": "2023-04-28T06:28:10.858Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-28T06:29:25.453Z"
   },
   {
    "duration": 103,
    "start_time": "2023-04-28T06:29:25.460Z"
   },
   {
    "duration": 18,
    "start_time": "2023-04-28T06:29:25.565Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-28T06:29:25.585Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-28T06:29:25.592Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-28T06:29:25.605Z"
   },
   {
    "duration": 220,
    "start_time": "2023-04-28T06:29:25.617Z"
   },
   {
    "duration": 18,
    "start_time": "2023-04-28T06:29:25.839Z"
   },
   {
    "duration": 15,
    "start_time": "2023-04-28T06:29:25.860Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-28T06:29:25.878Z"
   },
   {
    "duration": 15,
    "start_time": "2023-04-28T06:29:25.892Z"
   },
   {
    "duration": 14,
    "start_time": "2023-04-28T06:29:25.933Z"
   },
   {
    "duration": 38,
    "start_time": "2023-04-28T06:29:25.949Z"
   },
   {
    "duration": 151,
    "start_time": "2023-04-28T06:29:25.988Z"
   },
   {
    "duration": 28,
    "start_time": "2023-04-28T06:29:45.003Z"
   },
   {
    "duration": 11916,
    "start_time": "2023-04-28T06:29:49.429Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
